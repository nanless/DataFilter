"""
éŸ³é¢‘è´¨é‡ç­›é€‰æ¨¡å—
é›†æˆWhisperè¯­éŸ³è¯†åˆ«å’Œå¤šç§MOSè´¨é‡è¯„ä¼°
åŸºäºç°æœ‰speech_filteræ¡†æ¶
"""
import os
import sys
import json
import logging
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from pathlib import Path

# æ·»åŠ speech_filteråˆ°è·¯å¾„
speech_filter_path = os.path.join(os.path.dirname(__file__), '..', 'speech_filter')

# å¯¼å…¥speech_filteræ¨¡å—çš„åŠŸèƒ½
try:
    # ä¸´æ—¶æ·»åŠ speech_filterè·¯å¾„åˆ°sys.pathå¼€å¤´
    if speech_filter_path not in sys.path:
        sys.path.insert(0, speech_filter_path)
        
    from speech_recognizer import SpeechRecognizer, ASRResult
    from audio_quality_assessor import AudioQualityAssessor, AudioQualityResult
    
    # ä½¿ç”¨ç»å¯¹è·¯å¾„å¯¼å…¥speech_filterçš„config
    import importlib.util
    config_spec = importlib.util.spec_from_file_location(
        "speech_filter_config", 
        os.path.join(speech_filter_path, "config.py")
    )
    speech_filter_config = importlib.util.module_from_spec(config_spec)
    config_spec.loader.exec_module(speech_filter_config)
    
    ASRConfig = speech_filter_config.ASRConfig
    AudioQualityConfig = speech_filter_config.AudioQualityConfig
    ProcessingConfig = speech_filter_config.ProcessingConfig
    
    # ç§»é™¤æ·»åŠ çš„pathé¿å…å½±å“å…¶ä»–å¯¼å…¥
    if speech_filter_path in sys.path:
        sys.path.remove(speech_filter_path)
        
    SPEECH_FILTER_AVAILABLE = True
except ImportError as e:
    print(f"è­¦å‘Š: æ— æ³•å¯¼å…¥speech_filteræ¨¡å—: {e}")
    print("è¯·ç¡®ä¿speech_filteræ¨¡å—åœ¨æ­£ç¡®çš„è·¯å¾„ä¸‹ï¼Œæˆ–å®‰è£…ç›¸å…³ä¾èµ–")
    SPEECH_FILTER_AVAILABLE = False
    
    # åˆ›å»ºå ä½ç¬¦ç±»ä»¥é¿å…å¯¼å…¥é”™è¯¯
    class SpeechRecognizer:
        def __init__(self, config): pass
        def transcribe_audio_detailed(self, path): 
            class Result:
                success = False
                error_message = "speech_filteræ¨¡å—ä¸å¯ç”¨"
            return Result()
    
    class AudioQualityAssessor:
        def __init__(self, config): pass
        def assess_audio_quality_detailed(self, path):
            class Result:
                success = False
                error_message = "speech_filteræ¨¡å—ä¸å¯ç”¨"
                scores = {}
            return Result()
    
    class ASRConfig:
        def __init__(self, **kwargs): 
            for k, v in kwargs.items():
                setattr(self, k, v)
    
    class AudioQualityConfig:
        def __init__(self, **kwargs): 
            for k, v in kwargs.items():
                setattr(self, k, v)
        
    class ProcessingConfig:
        def __init__(self, **kwargs): 
            self.sample_rate = 16000  # é»˜è®¤é‡‡æ ·ç‡
            for k, v in kwargs.items():
                setattr(self, k, v)

logger = logging.getLogger(__name__)

@dataclass
class AudioSegmentQuality:
    """éŸ³é¢‘ç‰‡æ®µè´¨é‡ä¿¡æ¯"""
    audio_path: str
    passed: bool
    transcription: Optional[Dict[str, Any]] = None
    quality_scores: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None

class LongAudioQualityFilter:
    """é•¿éŸ³é¢‘è´¨é‡ç­›é€‰å™¨"""
    
    def __init__(self, config):
        self.config = config
        
        logger.info("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–é•¿éŸ³é¢‘è´¨é‡ç­›é€‰å™¨...")
        
        # æ£€æŸ¥speech_filteræ¨¡å—å¯ç”¨æ€§
        if not SPEECH_FILTER_AVAILABLE:
            logger.error("âŒ speech_filteræ¨¡å—ä¸å¯ç”¨!")
            logger.error("   è¿™å°†å¯¼è‡´æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µè¢«æ ‡è®°ä¸ºå¤±è´¥")
            logger.error("   è¯·æ£€æŸ¥:")
            logger.error("   1. speech_filterç›®å½•æ˜¯å¦å­˜åœ¨äº: ../speech_filter")
            logger.error("   2. å¿…è¦ä¾èµ–æ˜¯å¦å·²å®‰è£…: pip install gin-config torch torchaudio transformers")
            logger.error("   3. speech_filteræ¨¡å—æ˜¯å¦å®Œæ•´")
        else:
            logger.info("âœ… speech_filteræ¨¡å—å¯ç”¨")
        
        # åˆ›å»ºå…¼å®¹çš„é…ç½®å¯¹è±¡
        self.asr_config = self._create_asr_config()
        self.quality_config = self._create_quality_config()
        self.processing_config = self._create_processing_config()
        
        # åˆ›å»ºä¸€ä¸ªå…¼å®¹çš„é…ç½®å¯¹è±¡ç”¨äºåˆå§‹åŒ–æ¨¡å—
        self.compat_config = self._create_compat_config()
        
        # è®°å½•é…ç½®ä¿¡æ¯
        logger.info("ğŸ“‹ è´¨é‡ç­›é€‰é…ç½®:")
        logger.info(f"   ğŸ¤ Whisperæ¨¡å‹: {self.config.whisper.model_name}")
        logger.info(f"   ğŸ”¤ æœ€å°‘è¯æ•°: {self.config.quality_filter.min_words}")
        logger.info(f"   ğŸ“Š è´¨é‡é˜ˆå€¼:")
        if self.config.quality_filter.use_distil_mos:
            logger.info(f"      â€¢ DistilMOS â‰¥ {self.config.quality_filter.distil_mos_threshold}")
        if self.config.quality_filter.use_dnsmos:
            logger.info(f"      â€¢ DNSMOS â‰¥ {self.config.quality_filter.dnsmos_threshold}")
        if self.config.quality_filter.use_dnsmospro:
            logger.info(f"      â€¢ DNSMOSPro â‰¥ {self.config.quality_filter.dnsmospro_threshold}")
        
        # åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨
        logger.info("ğŸ¤ æ­£åœ¨åˆå§‹åŒ–Whisperè¯­éŸ³è¯†åˆ«å™¨...")
        try:
            self.speech_recognizer = SpeechRecognizer(self.compat_config)
            logger.info("âœ… æˆåŠŸåˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨")
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨å¤±è´¥: {e}")
            logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            self.speech_recognizer = None
            
        # åˆå§‹åŒ–éŸ³è´¨è¯„ä¼°å™¨
        logger.info("ğŸµ æ­£åœ¨åˆå§‹åŒ–MOSéŸ³è´¨è¯„ä¼°å™¨...")
        try:
            self.quality_assessor = AudioQualityAssessor(self.compat_config)
            logger.info("âœ… æˆåŠŸåˆå§‹åŒ–éŸ³è´¨è¯„ä¼°å™¨")
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–éŸ³è´¨è¯„ä¼°å™¨å¤±è´¥: {e}")
            logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            self.quality_assessor = None
        
        # æœ€ç»ˆçŠ¶æ€æ£€æŸ¥
        if self.speech_recognizer and self.quality_assessor:
            logger.info("ğŸ‰ è´¨é‡ç­›é€‰å™¨åˆå§‹åŒ–å®Œæˆ - æ‰€æœ‰ç»„ä»¶æ­£å¸¸")
        else:
            logger.error("âš ï¸ è´¨é‡ç­›é€‰å™¨åˆå§‹åŒ–ä¸å®Œæ•´:")
            if not self.speech_recognizer:
                logger.error("   âŒ è¯­éŸ³è¯†åˆ«å™¨ä¸å¯ç”¨")
            if not self.quality_assessor:
                logger.error("   âŒ éŸ³è´¨è¯„ä¼°å™¨ä¸å¯ç”¨")
            logger.error("   è¿™å°†å¯¼è‡´æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µè¯„ä¼°å¤±è´¥")
    
    def _create_asr_config(self) -> ASRConfig:
        """åˆ›å»ºASRé…ç½®"""
        return ASRConfig(
            model_name=self.config.whisper.model_name,
            language=self.config.whisper.language,
            batch_size=self.config.whisper.batch_size,
            device=self.config.whisper.device,
            min_words=self.config.quality_filter.min_words,
            model_cache_dir=self.config.whisper.model_cache_dir
        )
    
    def _create_quality_config(self) -> AudioQualityConfig:
        """åˆ›å»ºéŸ³è´¨é…ç½®"""
        quality_config = AudioQualityConfig(
            distil_mos_threshold=self.config.quality_filter.distil_mos_threshold,
            dnsmos_threshold=self.config.quality_filter.dnsmos_threshold,
            dnsmospro_threshold=self.config.quality_filter.dnsmospro_threshold,
            use_distil_mos=self.config.quality_filter.use_distil_mos,
            use_dnsmos=self.config.quality_filter.use_dnsmos,
            use_dnsmospro=self.config.quality_filter.use_dnsmospro
        )
        
        # å¦‚æœé…ç½®ä¸­æœ‰GPUè®¾å¤‡ä¿¡æ¯ï¼Œä¼ é€’ç»™éŸ³è´¨é…ç½®
        if hasattr(self.config, '_gpu_device'):
            quality_config.device = self.config._gpu_device
        
        return quality_config
    
    def _create_processing_config(self) -> ProcessingConfig:
        """åˆ›å»ºå¤„ç†é…ç½®"""
        return ProcessingConfig(
            supported_formats=self.config.processing.supported_formats,
            sample_rate=self.config.processing.sample_rate
        )
    
    def _create_compat_config(self):
        """åˆ›å»ºå…¼å®¹çš„é…ç½®å¯¹è±¡"""
        class CompatConfig:
            def __init__(self, asr_config, quality_config, processing_config):
                self.asr = asr_config
                self.audio_quality = quality_config
                self.processing = processing_config
                self.sample_rate = processing_config.sample_rate
        
        return CompatConfig(self.asr_config, self.quality_config, self.processing_config)
    
    def evaluate_audio_segment(self, audio_path: str) -> AudioSegmentQuality:
        """
        è¯„ä¼°å•ä¸ªéŸ³é¢‘ç‰‡æ®µçš„è´¨é‡
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            AudioSegmentQuality: è´¨é‡è¯„ä¼°ç»“æœ
        """
        logger.info(f"ğŸ” å¼€å§‹è¯„ä¼°éŸ³é¢‘ç‰‡æ®µ: {Path(audio_path).name}")
        
        result = AudioSegmentQuality(
            audio_path=audio_path,
            passed=False
        )
        
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not Path(audio_path).exists():
                result.error_message = f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}"
                logger.error(f"âŒ {result.error_message}")
                return result
            
            # æ­¥éª¤1: è¯­éŸ³è¯†åˆ«
            if not self.speech_recognizer:
                result.error_message = "è¯­éŸ³è¯†åˆ«å™¨æœªåˆå§‹åŒ– - speech_filteræ¨¡å—ä¸å¯ç”¨"
                logger.error(f"âŒ {result.error_message}")
                return result
                
            logger.info("ğŸ¤ æ­¥éª¤1/2: è¿›è¡ŒWhisperè¯­éŸ³è¯†åˆ«...")
            asr_result = self.speech_recognizer.transcribe_audio_detailed(audio_path)
            
            if not asr_result.success:
                result.error_message = f"Whisperè¯†åˆ«å¤±è´¥: {asr_result.error_message}"
                logger.error(f"âŒ {result.error_message}")
                return result
            
            # è®°å½•è¯†åˆ«ç»“æœçš„è¯¦ç»†ä¿¡æ¯
            result.transcription = {
                'text': asr_result.text,
                'language': asr_result.language,
                'word_count': asr_result.word_count,
                'confidence': asr_result.confidence,
                'segments': asr_result.segments
            }
            
            logger.info(f"âœ… Whisperè¯†åˆ«æˆåŠŸ:")
            logger.info(f"   ğŸ“ è¯†åˆ«æ–‡æœ¬: '{asr_result.text[:50]}{'...' if len(asr_result.text) > 50 else ''}'")
            logger.info(f"   ğŸ”¤ è¯­è¨€: {asr_result.language}")
            logger.info(f"   ğŸ“Š è¯æ•°: {asr_result.word_count}")
            confidence_str = f"{asr_result.confidence:.3f}" if asr_result.confidence is not None else "N/A"
            logger.info(f"   ğŸ¯ ç½®ä¿¡åº¦: {confidence_str}")
            
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ–‡å­—è¯†åˆ«è¦æ±‚
            if self.config.quality_filter.require_text and not asr_result.text.strip():
                result.error_message = "æœªè¯†åˆ«åˆ°æ–‡å­—å†…å®¹"
                logger.warning(f"âš ï¸ {result.error_message}")
                return result
                
            if asr_result.word_count < self.config.quality_filter.min_words:
                result.error_message = f"è¯æ•°ä¸è¶³ï¼Œè¦æ±‚è‡³å°‘{self.config.quality_filter.min_words}è¯ï¼Œå®é™…{asr_result.word_count}è¯"
                logger.warning(f"âš ï¸ {result.error_message}")
                return result
            
            logger.info(f"âœ… æ–‡æœ¬è¦æ±‚æ£€æŸ¥é€šè¿‡ - è¯æ•°{asr_result.word_count}â‰¥{self.config.quality_filter.min_words}")
            
            # æ­¥éª¤2: éŸ³è´¨è¯„ä¼°
            if not self.quality_assessor:
                result.error_message = "éŸ³è´¨è¯„ä¼°å™¨æœªåˆå§‹åŒ– - speech_filteræ¨¡å—ä¸å¯ç”¨"
                logger.error(f"âŒ {result.error_message}")
                return result
                
            logger.info("ğŸµ æ­¥éª¤2/2: è¿›è¡ŒMOSéŸ³è´¨è¯„ä¼°...")
            quality_result = self.quality_assessor.assess_audio_quality_detailed(audio_path)
            
            if not quality_result.success:
                result.error_message = f"MOSéŸ³è´¨è¯„ä¼°å¤±è´¥: {quality_result.error_message}"
                logger.error(f"âŒ {result.error_message}")
                return result
            
            result.quality_scores = quality_result.scores
            
            # è¯¦ç»†è®°å½•MOSè¯„åˆ†
            logger.info(f"âœ… MOSéŸ³è´¨è¯„åˆ†ç»“æœ:")
            for metric, score in quality_result.scores.items():
                logger.info(f"   ğŸ“ˆ {metric}: {score:.3f}")
            
            # æ£€æŸ¥å„é¡¹MOSåˆ†æ•°æ˜¯å¦æ»¡è¶³é˜ˆå€¼
            quality_passed = True
            failed_metrics = []
            passed_metrics = []
            
            if self.config.quality_filter.use_distil_mos:
                distilmos_score = quality_result.scores.get('distilmos', 0.0)
                threshold = self.config.quality_filter.distil_mos_threshold
                if distilmos_score < threshold:
                    quality_passed = False
                    failed_metrics.append(f"DistilMOS({distilmos_score:.3f} < {threshold})")
                else:
                    passed_metrics.append(f"DistilMOS({distilmos_score:.3f} â‰¥ {threshold})")
            
            if self.config.quality_filter.use_dnsmos:
                # æŸ¥æ‰¾å¯èƒ½çš„DNSMOSé”®å
                dnsmos_score = (quality_result.scores.get('dnsmos_overall') or 
                               quality_result.scores.get('dnsmos_ovrl') or 
                               quality_result.scores.get('dnsmos') or 0.0)
                threshold = self.config.quality_filter.dnsmos_threshold
                if dnsmos_score < threshold:
                    quality_passed = False
                    failed_metrics.append(f"DNSMOS({dnsmos_score:.3f} < {threshold})")
                else:
                    passed_metrics.append(f"DNSMOS({dnsmos_score:.3f} â‰¥ {threshold})")
            
            if self.config.quality_filter.use_dnsmospro:
                dnsmospro_score = (quality_result.scores.get('dnsmospro_overall') or
                                  quality_result.scores.get('dnsmospro') or 0.0)
                threshold = self.config.quality_filter.dnsmospro_threshold
                if dnsmospro_score < threshold:
                    quality_passed = False
                    failed_metrics.append(f"DNSMOSPro({dnsmospro_score:.3f} < {threshold})")
                else:
                    passed_metrics.append(f"DNSMOSPro({dnsmospro_score:.3f} â‰¥ {threshold})")
            
            # è®°å½•é˜ˆå€¼æ£€æŸ¥ç»“æœ
            if passed_metrics:
                logger.info(f"âœ… é€šè¿‡çš„æŒ‡æ ‡: {', '.join(passed_metrics)}")
            
            if not quality_passed:
                result.error_message = f"éŸ³è´¨è¯„åˆ†ä¸æ»¡è¶³è¦æ±‚: {', '.join(failed_metrics)}"
                logger.warning(f"âš ï¸ {result.error_message}")
                return result
            
            # æ‰€æœ‰æ£€æŸ¥é€šè¿‡
            result.passed = True
            logger.info(f"ğŸ‰ éŸ³é¢‘ç‰‡æ®µè´¨é‡è¯„ä¼°å…¨éƒ¨é€šè¿‡: {Path(audio_path).name}")
            
        except Exception as e:
            logger.error(f"ğŸ’¥ è¯„ä¼°éŸ³é¢‘ç‰‡æ®µæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            logger.exception("è¯¦ç»†å¼‚å¸¸ä¿¡æ¯:")
            result.error_message = str(e)
        
        return result
    
    def batch_evaluate_segments(self, audio_files: List[str]) -> List[AudioSegmentQuality]:
        """
        æ‰¹é‡è¯„ä¼°éŸ³é¢‘ç‰‡æ®µ
        
        Args:
            audio_files: éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            List[AudioSegmentQuality]: è¯„ä¼°ç»“æœåˆ—è¡¨
        """
        results = []
        
        logger.info(f"ğŸ¯ å¼€å§‹æ‰¹é‡è¯„ä¼° {len(audio_files)} ä¸ªéŸ³é¢‘ç‰‡æ®µ")
        
        # æ£€æŸ¥æ¨¡å—å¯ç”¨æ€§
        if not SPEECH_FILTER_AVAILABLE:
            logger.error("âŒ speech_filteræ¨¡å—ä¸å¯ç”¨ï¼Œæ‰€æœ‰éŸ³é¢‘å°†è¢«æ ‡è®°ä¸ºå¤±è´¥")
            logger.error("   è¯·å®‰è£…ç›¸å…³ä¾èµ–ï¼špip install gin-config")
            
        passed_count = 0
        failed_reasons = {}
        
        for i, audio_file in enumerate(audio_files, 1):
            logger.info(f"ğŸ“‹ è¯„ä¼°è¿›åº¦: {i}/{len(audio_files)} ({i/len(audio_files)*100:.1f}%)")
            result = self.evaluate_audio_segment(audio_file)
            results.append(result)
            
            # ç»Ÿè®¡ç»“æœ
            if result.passed:
                passed_count += 1
                logger.info(f"âœ… ç¬¬{i}ä¸ªéŸ³é¢‘é€šè¿‡è¯„ä¼°")
            else:
                # ç»Ÿè®¡å¤±è´¥åŸå› 
                reason = result.error_message or "æœªçŸ¥é”™è¯¯"
                failed_reasons[reason] = failed_reasons.get(reason, 0) + 1
                logger.info(f"âŒ ç¬¬{i}ä¸ªéŸ³é¢‘æœªé€šè¿‡è¯„ä¼°: {reason}")
        
        # è¾“å‡ºè¯¦ç»†çš„æ±‡æ€»ç»Ÿè®¡
        pass_rate = passed_count / len(results) * 100 if results else 0
        logger.info(f"")
        logger.info(f"ğŸ“Š === æ‰¹é‡è¯„ä¼°å®Œæˆæ±‡æ€» ===")
        logger.info(f"âœ… é€šè¿‡æ•°é‡: {passed_count}/{len(results)} ({pass_rate:.1f}%)")
        logger.info(f"âŒ å¤±è´¥æ•°é‡: {len(results) - passed_count}")
        
        if failed_reasons:
            logger.info(f"ğŸ” å¤±è´¥åŸå› ç»Ÿè®¡:")
            for reason, count in sorted(failed_reasons.items(), key=lambda x: x[1], reverse=True):
                logger.info(f"   â€¢ {reason}: {count}æ¬¡ ({count/len(results)*100:.1f}%)")
        
        # å¦‚æœé€šè¿‡ç‡ä¸º0ï¼Œç»™å‡ºè¯Šæ–­å»ºè®®
        if passed_count == 0 and len(results) > 0:
            logger.error(f"")
            logger.error(f"âš ï¸ === 0%é€šè¿‡ç‡è¯Šæ–­ ===")
            if not SPEECH_FILTER_AVAILABLE:
                logger.error(f"ğŸ”§ ä¸»è¦é—®é¢˜: speech_filteræ¨¡å—ä¸å¯ç”¨")
                logger.error(f"   è§£å†³æ–¹æ¡ˆ: ç¡®ä¿speech_filterç›®å½•å­˜åœ¨ä¸”åŒ…å«æ­£ç¡®çš„æ¨¡å—")
                logger.error(f"   æ£€æŸ¥ä¾èµ–: pip install gin-config torch torchaudio transformers")
            else:
                logger.error(f"ğŸ”§ å¯èƒ½çš„é—®é¢˜:")
                logger.error(f"   1. è´¨é‡é˜ˆå€¼è®¾ç½®è¿‡é«˜")
                logger.error(f"   2. éŸ³é¢‘è´¨é‡ç¡®å®è¾ƒå·®")
                logger.error(f"   3. æ¨¡å‹åŠ è½½æˆ–æ¨ç†é—®é¢˜")
        
        return results
    
    def filter_and_save_results(self, evaluation_results: List[AudioSegmentQuality], 
                               output_dir: str, audio_id: str, speaker_id: str) -> Dict[str, Any]:
        """
        ç­›é€‰å¹¶ä¿å­˜é€šè¿‡è´¨é‡æ£€æŸ¥çš„éŸ³é¢‘ç‰‡æ®µ
        
        Args:
            evaluation_results: è¯„ä¼°ç»“æœåˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            audio_id: éŸ³é¢‘ID
            speaker_id: è¯´è¯äººID
            
        Returns:
            ä¿å­˜ç»“æœç»Ÿè®¡
        """
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        speaker_output_dir = Path(output_dir) / audio_id / speaker_id
        speaker_output_dir.mkdir(parents=True, exist_ok=True)
        
        saved_files = []
        metadata_files = []
        
        # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶åå‰ç¼€ï¼ŒåŒ…å«æ—¶é—´æˆ³å’Œè¿›ç¨‹ä¿¡æ¯
        import time
        import os
        import uuid
        
        # è·å–è¿›ç¨‹IDå’Œæ—¶é—´æˆ³ç”¨äºç”Ÿæˆå”¯ä¸€å‰ç¼€
        process_id = getattr(self.config, '_process_id', os.getpid())
        timestamp = int(time.time() * 1000)  # æ¯«ç§’æ—¶é—´æˆ³
        unique_prefix = f"{timestamp}_{process_id}"
        
        segment_counter = 1
        for result in evaluation_results:
            if result.passed:
                # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶
                src_path = Path(result.audio_path)
                dst_filename = f"segment_{unique_prefix}_{segment_counter:03d}.wav"
                dst_path = speaker_output_dir / dst_filename
                
                # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ éšæœºåç¼€ï¼ˆæå°‘å‘ç”Ÿï¼‰
                if dst_path.exists():
                    random_suffix = str(uuid.uuid4())[:8]
                    dst_filename = f"segment_{unique_prefix}_{segment_counter:03d}_{random_suffix}.wav"
                    dst_path = speaker_output_dir / dst_filename
                
                try:
                    import shutil
                    shutil.copy2(src_path, dst_path)
                    saved_files.append(str(dst_path))
                    
                    # ä¿å­˜å…ƒæ•°æ®
                    metadata = {
                        'segment_id': f"{unique_prefix}_{segment_counter:03d}",
                        'segment_counter': segment_counter,
                        'process_id': process_id,
                        'timestamp': timestamp,
                        'original_path': str(src_path),
                        'saved_path': str(dst_path),
                        'audio_id': audio_id,
                        'speaker_id': speaker_id,
                        'transcription': result.transcription,
                        'quality_scores': result.quality_scores,
                        'evaluation_passed': True,
                        'processing_timestamp': self._get_timestamp()
                    }
                    
                    # æ¸…ç†å…ƒæ•°æ®ï¼Œç¡®ä¿å¯ä»¥JSONåºåˆ—åŒ–
                    clean_metadata = self._clean_for_json_serialization(metadata)
                    
                    metadata_filename = f"segment_{unique_prefix}_{segment_counter:03d}.json"
                    metadata_path = speaker_output_dir / metadata_filename
                    
                    # å¦‚æœå…ƒæ•°æ®æ–‡ä»¶å·²å­˜åœ¨ï¼Œä½¿ç”¨åŒæ ·çš„éšæœºåç¼€
                    if metadata_path.exists():
                        if 'random_suffix' in locals():
                            metadata_filename = f"segment_{unique_prefix}_{segment_counter:03d}_{random_suffix}.json"
                            metadata_path = speaker_output_dir / metadata_filename
                    
                    with open(metadata_path, 'w', encoding='utf-8') as f:
                        json.dump(clean_metadata, f, ensure_ascii=False, indent=2)
                    
                    metadata_files.append(str(metadata_path))
                    segment_counter += 1
                    
                except Exception as e:
                    logger.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥ {src_path} -> {dst_path}: {e}")
        
        summary = {
            'audio_id': audio_id,
            'speaker_id': speaker_id,
            'total_segments': len(evaluation_results),
            'passed_segments': len(saved_files),
            'saved_files': saved_files,
            'metadata_files': metadata_files,
            'output_directory': str(speaker_output_dir),
            'pass_rate': len(saved_files) / len(evaluation_results) if evaluation_results else 0.0,
            'unique_prefix': unique_prefix,  # æ·»åŠ å”¯ä¸€å‰ç¼€ä¿¡æ¯
            'process_id': process_id
        }
        
        logger.info(f"ä¿å­˜å®Œæˆ - {audio_id}/{speaker_id}: {len(saved_files)}/{len(evaluation_results)} ä¸ªç‰‡æ®µé€šè¿‡ç­›é€‰ ({summary['pass_rate']:.1%})")
        
        return summary
    
    def evaluate_audio_array(self, audio_array, metadata: Dict[str, Any]) -> AudioSegmentQuality:
        """
        è¯„ä¼°éŸ³é¢‘æ•°ç»„è´¨é‡ï¼ˆä¸ä¿å­˜ä¸ºæ–‡ä»¶ï¼‰
        
        Args:
            audio_array: éŸ³é¢‘æ•°ç»„
            metadata: éŸ³é¢‘å…ƒæ•°æ®
            
        Returns:
            AudioSegmentQuality: è´¨é‡è¯„ä¼°ç»“æœ
        """
        try:
            import tempfile
            import soundfile as sf
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_path = temp_file.name
                
                # ä¿å­˜éŸ³é¢‘æ•°ç»„åˆ°ä¸´æ—¶æ–‡ä»¶
                sf.write(temp_path, audio_array, metadata.get('sample_rate', self.config.processing.sample_rate))
                
                # è¯„ä¼°éŸ³é¢‘è´¨é‡
                result = self.evaluate_audio_segment(temp_path)
                
                # æ›´æ–°è·¯å¾„ä¿¡æ¯
                result.audio_path = f"segment_{metadata.get('segment_id', 0)}"
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(temp_path)
                except:
                    pass
                
                return result
                
        except Exception as e:
            logger.error(f"è¯„ä¼°éŸ³é¢‘æ•°ç»„è´¨é‡å¤±è´¥: {e}")
            return AudioSegmentQuality(
                audio_path=f"segment_{metadata.get('segment_id', 0)}",
                passed=False,
                error_message=str(e)
            )
    
    def process_speaker_audio_segments(self, speaker_audio_segments: Dict[str, List], 
                                     audio_id: str, output_dir: str) -> Dict[str, Any]:
        """
        å¤„ç†è¯´è¯äººéŸ³é¢‘ç‰‡æ®µ
        
        Args:
            speaker_audio_segments: {speaker_id: [(audio_array, metadata), ...]}
            audio_id: éŸ³é¢‘ID
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        all_results = {}
        total_segments = 0
        total_passed = 0
        
        logger.info(f"ğŸ­ å¼€å§‹å¤„ç† {len(speaker_audio_segments)} ä¸ªè¯´è¯äººçš„éŸ³é¢‘ç‰‡æ®µ")
        
        for i, (speaker_id, segments) in enumerate(speaker_audio_segments.items(), 1):
            logger.info(f"ğŸ‘¤ å¤„ç†è¯´è¯äºº {i}/{len(speaker_audio_segments)}: {speaker_id} ({len(segments)} ä¸ªç‰‡æ®µ)")
            
            # è¯„ä¼°æ¯ä¸ªéŸ³é¢‘ç‰‡æ®µ
            evaluation_results = self.batch_evaluate_segments([
                self._save_temp_audio(audio_array, metadata) 
                for audio_array, metadata in segments
            ])
            
            # ä¿å­˜é€šè¿‡è´¨é‡æ£€æŸ¥çš„ç‰‡æ®µ
            save_result = self.save_audio_segments(
                segments, evaluation_results, output_dir, audio_id, speaker_id
            )
            
            all_results[speaker_id] = save_result
            total_segments += save_result['total_segments']
            total_passed += save_result['passed_segments']
            
            logger.info(f"âœ… è¯´è¯äºº {speaker_id} å®Œæˆ: {save_result['passed_segments']}/{save_result['total_segments']} ä¸ªç‰‡æ®µé€šè¿‡ ({save_result['pass_rate']:.1%})")
        
        summary = {
            'audio_id': audio_id,
            'speaker_results': all_results,
            'total_segments': total_segments,
            'total_passed': total_passed,
            'overall_pass_rate': total_passed / total_segments if total_segments > 0 else 0.0
        }
        
        logger.info(f"")
        logger.info(f"ğŸ¯ === {audio_id} å¤„ç†å®Œæˆæ±‡æ€» ===")
        logger.info(f"ğŸ‘¥ å¤„ç†è¯´è¯äºº: {len(speaker_audio_segments)} ä¸ª")
        logger.info(f"ğŸµ æ€»éŸ³é¢‘ç‰‡æ®µ: {total_segments} ä¸ª")
        logger.info(f"âœ… é€šè¿‡ç­›é€‰: {total_passed} ä¸ª")
        logger.info(f"ğŸ“Š æ€»é€šè¿‡ç‡: {summary['overall_pass_rate']:.1%}")
        
        # æŒ‰è¯´è¯äººæ˜¾ç¤ºè¯¦ç»†ç»“æœ
        for speaker_id, result in all_results.items():
            logger.info(f"   ğŸ‘¤ {speaker_id}: {result['passed_segments']}/{result['total_segments']} ({result['pass_rate']:.1%})")
        
        return summary
    
    def _save_temp_audio(self, audio_array, metadata):
        """ä¿å­˜ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ç”¨äºè¯„ä¼°"""
        import tempfile
        import soundfile as sf
        import os
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        temp_fd, temp_path = tempfile.mkstemp(suffix='.wav')
        os.close(temp_fd)
        
        # å†™å…¥éŸ³é¢‘æ•°æ®
        sf.write(temp_path, audio_array, metadata.get('sample_rate', self.config.processing.sample_rate))
        
        return temp_path
    
    def save_audio_segments(self, segments, evaluation_results, output_dir: str, 
                           audio_id: str, speaker_id: str) -> Dict[str, Any]:
        """
        ä¿å­˜éŸ³é¢‘ç‰‡æ®µå’Œå…ƒæ•°æ®
        
        Args:
            segments: [(audio_array, metadata), ...]
            evaluation_results: è¯„ä¼°ç»“æœåˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            audio_id: éŸ³é¢‘ID
            speaker_id: è¯´è¯äººID
            
        Returns:
            ä¿å­˜ç»“æœç»Ÿè®¡
        """
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        speaker_output_dir = Path(output_dir) / audio_id / speaker_id
        speaker_output_dir.mkdir(parents=True, exist_ok=True)
        
        saved_files = []
        metadata_files = []
        
        # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶åå‰ç¼€ï¼ŒåŒ…å«æ—¶é—´æˆ³å’Œè¿›ç¨‹ä¿¡æ¯
        import time
        import os
        import uuid
        
        # è·å–è¿›ç¨‹IDå’Œæ—¶é—´æˆ³ç”¨äºç”Ÿæˆå”¯ä¸€å‰ç¼€
        process_id = getattr(self.config, '_process_id', os.getpid())
        timestamp = int(time.time() * 1000)  # æ¯«ç§’æ—¶é—´æˆ³
        unique_prefix = f"{timestamp}_{process_id}"
        
        segment_counter = 1
        for (audio_array, metadata), result in zip(segments, evaluation_results):
            if result.passed:
                try:
                    import soundfile as sf
                    
                    # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶åï¼šæ—¶é—´æˆ³_è¿›ç¨‹id_è®¡æ•°å™¨
                    dst_filename = f"segment_{unique_prefix}_{segment_counter:03d}.wav"
                    dst_path = speaker_output_dir / dst_filename
                    
                    # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ éšæœºåç¼€ï¼ˆæå°‘å‘ç”Ÿï¼‰
                    if dst_path.exists():
                        random_suffix = str(uuid.uuid4())[:8]
                        dst_filename = f"segment_{unique_prefix}_{segment_counter:03d}_{random_suffix}.wav"
                        dst_path = speaker_output_dir / dst_filename
                    
                    sf.write(str(dst_path), audio_array, metadata.get('sample_rate', self.config.processing.sample_rate))
                    saved_files.append(str(dst_path))
                    
                    # ä¿å­˜å®Œæ•´å…ƒæ•°æ®
                    full_metadata = {
                        'segment_id': f"{unique_prefix}_{segment_counter:03d}",
                        'segment_counter': segment_counter,
                        'process_id': process_id,
                        'timestamp': timestamp,
                        'saved_path': str(dst_path),
                        'audio_id': audio_id,
                        'speaker_id': speaker_id,
                        'original_metadata': metadata,
                        'transcription': result.transcription,
                        'quality_scores': result.quality_scores,
                        'evaluation_passed': True,
                        'processing_timestamp': self._get_timestamp()
                    }
                    
                    # æ¸…ç†å…ƒæ•°æ®ï¼Œç¡®ä¿å¯ä»¥JSONåºåˆ—åŒ–
                    clean_full_metadata = self._clean_for_json_serialization(full_metadata)
                    
                    metadata_filename = f"segment_{unique_prefix}_{segment_counter:03d}.json"
                    metadata_path = speaker_output_dir / metadata_filename
                    
                    # å¦‚æœå…ƒæ•°æ®æ–‡ä»¶å·²å­˜åœ¨ï¼Œä½¿ç”¨åŒæ ·çš„éšæœºåç¼€
                    if metadata_path.exists():
                        if 'random_suffix' in locals():
                            metadata_filename = f"segment_{unique_prefix}_{segment_counter:03d}_{random_suffix}.json"
                            metadata_path = speaker_output_dir / metadata_filename
                    
                    with open(metadata_path, 'w', encoding='utf-8') as f:
                        json.dump(clean_full_metadata, f, ensure_ascii=False, indent=2)
                    
                    metadata_files.append(str(metadata_path))
                    segment_counter += 1
                    
                except Exception as e:
                    logger.error(f"ä¿å­˜éŸ³é¢‘ç‰‡æ®µå¤±è´¥: {e}")
        
        summary = {
            'speaker_id': speaker_id,
            'total_segments': len(evaluation_results),
            'passed_segments': len(saved_files),
            'saved_files': saved_files,
            'metadata_files': metadata_files,
            'output_directory': str(speaker_output_dir),
            'pass_rate': len(saved_files) / len(evaluation_results) if evaluation_results else 0.0,
            'unique_prefix': unique_prefix,  # æ·»åŠ å”¯ä¸€å‰ç¼€ä¿¡æ¯
            'process_id': process_id
        }
        
        return summary
    
    def _clean_for_json_serialization(self, data):
        """æ¸…ç†æ•°æ®ä½¿å…¶å¯ä»¥JSONåºåˆ—åŒ–"""
        import math
        
        if isinstance(data, dict):
            return {k: self._clean_for_json_serialization(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [self._clean_for_json_serialization(item) for item in data]
        elif isinstance(data, float):
            # å¤„ç†NaNå’Œæ— ç©·å¤§
            if math.isnan(data) or math.isinf(data):
                return None
            return data
        elif data is None or isinstance(data, (str, int, bool)):
            return data
        else:
            # å¯¹äºå…¶ä»–ä¸å¯åºåˆ—åŒ–çš„ç±»å‹ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
            try:
                return str(data)
            except:
                return None

    def _get_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        import datetime
        return datetime.datetime.now().isoformat() 