#!/usr/bin/env python3
"""
å¤šGPUåŠŸèƒ½æµ‹è¯•è„šæœ¬
"""
import os
import sys
import torch
import time
import logging
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from config import load_config_from_yaml
from multi_gpu_pipeline import MultiGPUPipeline
from audio_quality_assessor import AudioQualityAssessor

def test_gpu_availability():
    """æµ‹è¯•GPUå¯ç”¨æ€§"""
    print("ğŸ” GPUå¯ç”¨æ€§æ£€æŸ¥")
    print("="*50)
    
    # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
    if torch.cuda.is_available():
        print("âœ… CUDAå¯ç”¨")
        gpu_count = torch.cuda.device_count()
        print(f"ğŸ“Š æ£€æµ‹åˆ° {gpu_count} å¼ GPU")
        
        # æ˜¾ç¤ºæ¯å¼ GPUçš„ä¿¡æ¯
        for i in range(gpu_count):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"   GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
        
        return gpu_count
    else:
        print("âŒ CUDAä¸å¯ç”¨")
        return 0

def test_multi_gpu_config():
    """æµ‹è¯•å¤šGPUé…ç½®"""
    print("=" * 60)
    print("æµ‹è¯•å¤šGPUé…ç½®")
    print("=" * 60)
    
    try:
        # from config import load_config_from_yaml
        # from multi_gpu_pipeline import MultiGPUPipeline # This import is no longer needed
        
        # åŠ è½½é…ç½®
        config = load_config_from_yaml()
        
        # æ£€æŸ¥GPUå¯ç”¨æ€§
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            print(f"âœ… CUDAå¯ç”¨ï¼Œæ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
            
            for i in range(gpu_count):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                print(f"  GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
            
            # æ£€æŸ¥æ¨¡å‹ç¼“å­˜ç›®å½•
            cache_dir = Path(config.asr.model_cache_dir)
            if cache_dir.exists():
                print(f"âœ… æ¨¡å‹ç¼“å­˜ç›®å½•å­˜åœ¨: {cache_dir}")
            else:
                print(f"âš ï¸ æ¨¡å‹ç¼“å­˜ç›®å½•ä¸å­˜åœ¨ï¼Œå°†åœ¨é¦–æ¬¡è¿è¡Œæ—¶åˆ›å»º: {cache_dir}")
            
            # æ£€æŸ¥DNSMOSProæ¨¡å‹æ–‡ä»¶
            dnsmospro_dir = cache_dir / "dnsmospro"
            model_path = dnsmospro_dir / "model_best.pt"
            
            if model_path.exists():
                print(f"âœ… DNSMOSProæ¨¡å‹æ–‡ä»¶å­˜åœ¨: {model_path}")
            else:
                print(f"âš ï¸ DNSMOSProæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åœ¨é¦–æ¬¡è¿è¡Œæ—¶ä»GitHubä¸‹è½½: {model_path}")
            
            return True
        else:
            print("âŒ CUDAä¸å¯ç”¨")
            return False
            
    except Exception as e:
        print(f"âŒ å¤šGPUé…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_gpu_memory_usage():
    """æµ‹è¯•GPUå†…å­˜ä½¿ç”¨"""
    print("\nğŸ’¾ GPUå†…å­˜ä½¿ç”¨æµ‹è¯•")
    print("="*50)
    
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼Œè·³è¿‡å†…å­˜æµ‹è¯•")
        return False
    
    try:
        # æµ‹è¯•æ¯å¼ GPUçš„å†…å­˜ä½¿ç”¨
        for i in range(torch.cuda.device_count()):
            torch.cuda.set_device(i)
            
            # æ¸…ç©ºGPUç¼“å­˜
            torch.cuda.empty_cache()
            
            # è·å–å†…å­˜ä¿¡æ¯
            memory_allocated = torch.cuda.memory_allocated(i) / 1024**3
            memory_reserved = torch.cuda.memory_reserved(i) / 1024**3
            memory_free = torch.cuda.get_device_properties(i).total_memory / 1024**3 - memory_reserved
            
            print(f"GPU {i}:")
            print(f"   å·²åˆ†é…: {memory_allocated:.2f}GB")
            print(f"   å·²ä¿ç•™: {memory_reserved:.2f}GB")
            print(f"   ç©ºé—²: {memory_free:.2f}GB")
        
        return True
        
    except Exception as e:
        print(f"âŒ GPUå†…å­˜æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åœ¨GPUä¸Šçš„åŠ è½½"""
    print("\nğŸ¤– æ¨¡å‹GPUåŠ è½½æµ‹è¯•")
    print("="*50)
    
    try:
        # from config import load_config_from_yaml
        # from audio_quality_assessor import AudioQualityAssessor
        
        config = load_config_from_yaml()
        
        # è®¾ç½®ä½¿ç”¨GPU
        config.asr.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        print(f"ç›®æ ‡è®¾å¤‡: {config.asr.device}")
        
        # åˆ›å»ºéŸ³è´¨è¯„ä¼°å™¨
        assessor = AudioQualityAssessor(config)
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åœ¨GPUä¸Š
        if torch.cuda.is_available():
            models_on_gpu = []
            
            # æ£€æŸ¥DistilMOSæ¨¡å‹
            if assessor.distilmos_model is not None:
                device = next(assessor.distilmos_model.parameters()).device
                models_on_gpu.append(f"DistilMOS: {device}")
            
            # æ£€æŸ¥DNSMOSProæ¨¡å‹
            if assessor.dnsmospro_model is not None:
                # æ£€æŸ¥JITæ¨¡å‹çš„è®¾å¤‡
                # è¿™é‡Œç®€åŒ–æ£€æŸ¥ï¼Œå®é™…ä½¿ç”¨æ—¶æ¨¡å‹ä¼šè¢«ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
                models_on_gpu.append("DNSMOSPro: cuda")
            
            if models_on_gpu:
                print("âœ… æ¨¡å‹GPUåŠ è½½æˆåŠŸ:")
                for model_info in models_on_gpu:
                    print(f"   {model_info}")
                return True
            else:
                print("âŒ æ²¡æœ‰æ¨¡å‹åŠ è½½åˆ°GPU")
                return False
        else:
            print("âš ï¸ ä½¿ç”¨CPUæ¨¡å¼")
            return True
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹GPUåŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å¤šGPUåŠŸèƒ½æµ‹è¯•")
    print("="*60)
    
    tests = [
        ("GPUå¯ç”¨æ€§æ£€æŸ¥", test_gpu_availability),
        ("å¤šGPUé…ç½®æµ‹è¯•", test_multi_gpu_config),
        ("GPUå†…å­˜ä½¿ç”¨æµ‹è¯•", test_gpu_memory_usage),
        ("æ¨¡å‹GPUåŠ è½½æµ‹è¯•", test_model_loading)
    ]
    
    success_count = 0
    total_count = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nğŸ” {test_name}")
        try:
            if test_func():
                print(f"âœ… {test_name}é€šè¿‡")
                success_count += 1
            else:
                print(f"âŒ {test_name}å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name}å¼‚å¸¸: {e}")
    
    # æµ‹è¯•æ€»ç»“
    print("\n" + "="*60)
    print(f"ğŸ¯ æµ‹è¯•å®Œæˆ: {success_count}/{total_count} é€šè¿‡")
    print("="*60)
    
    if success_count == total_count:
        print("ğŸ‰ å¤šGPUåŠŸèƒ½æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return 0
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 